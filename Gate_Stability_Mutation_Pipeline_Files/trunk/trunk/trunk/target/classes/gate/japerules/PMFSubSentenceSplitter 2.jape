Phase: PMFSubSentenceSplitter
Input: PMFSentence

Rule:ImpactSplitter
(
	{PMFSentence}
):pmfsentence
-->
{
	try {
		Annotation pmfSentenceA = (gate.Annotation)((gate.AnnotationSet)bindings.get("pmfsentence")).iterator().next();
		AnnotationSet mfAS = inputAS.get("MolecularFunction", pmfSentenceA.getStartNode().getOffset(),pmfSentenceA.getEndNode().getOffset());
			
		if(mfAS.size() > 1) {
			System.out.println("Splitting PMFSentence into subsentences..."+doc.getName()+"|"+doc.getContent().getContent(pmfSentenceA.getStartNode().getOffset(),pmfSentenceA.getEndNode().getOffset()));
			Map<Long,Long> mfMap = new HashMap<Long,Long>();
			for(Annotation mfA : mfAS) {
				mfMap.put(mfA.getStartNode().getOffset(),mfA.getEndNode().getOffset());
			}
			//split according to position
//System.out.println(mfMap.keySet());
			Long[] keys = (Long[]) mfMap.keySet().toArray(new Long[0]);
//System.out.println(keys[0]);
			Arrays.sort(keys);
	//System.out.println(keys);		
			int numberOfMfs = keys.length;
			//leftmost
			Long start = pmfSentenceA.getStartNode().getOffset();

			AnnotationSet tokens = inputAS.get("PMFToken",mfMap.get(keys[0]),
keys[1]);

			Map<Long,Annotation> tokenMap = new HashMap<Long,Annotation>();
			for(Annotation token : tokens) {
				tokenMap.put(token.getStartNode().getOffset(),token);
			}

			Long[] tokenKeys = (Long[]) tokenMap.keySet().toArray(new Long[0]);
			Arrays.sort(tokenKeys);

			long subSentenceEnd = keys[1];

			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceEnd = tokenStart;
					break;
				}
			}
			//export
			outputAS.add(start,subSentenceEnd,"PMFSentence",Factory.newFeatureMap());
			
			//middle
			for(int i = 1; i < numberOfMfs-1; i++) {
				//from left..
				tokens = inputAS.get("PMFToken",mfMap.get(keys[i-1]),keys[i]);
				tokenMap.clear();
				for(Annotation token : tokens) {
					tokenMap.put(token.getStartNode().getOffset(),token);
				}
				tokenKeys = (Long[])tokenMap.keySet().toArray(new Long[0]);
				Arrays.sort(tokenKeys);
				long subSentenceStart = mfMap.get(keys[i-1]);
				for(Long tokenStart : tokenKeys) {
					Annotation token = tokenMap.get(tokenStart);
					Long tokenEnd = token.getEndNode().getOffset();
					FeatureMap features = token.getFeatures();
					if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
						subSentenceStart = tokenEnd;
					}
				}
				
				//..to right
				tokens = inputAS.get("PMFToken",mfMap.get(keys[i]),keys[i+1]);
				tokenMap.clear();
				for(Annotation token : tokens) {
					tokenMap.put(token.getStartNode().getOffset(),token);
				}
				tokenKeys = (Long[])tokenMap.keySet().toArray(new Long[0]);
				Arrays.sort(tokenKeys);
				subSentenceEnd = keys[i+1];
				for(long tokenStart : tokenKeys) {
					Annotation token = tokenMap.get(tokenStart);
					long tokenEnd = token.getEndNode().getOffset();
					FeatureMap features = token.getFeatures();
					if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
						subSentenceEnd = tokenStart;
						break;
					}
				}
				
				//export
				outputAS.add(subSentenceStart+1,subSentenceEnd,"PMFSentence",Factory.newFeatureMap());
			}

			//rightmost
			tokens = inputAS.get("PMFToken",mfMap.get(keys[numberOfMfs-2]),keys[numberOfMfs-1]);
			tokenMap.clear();
			for(Annotation token : tokens) {
				tokenMap.put(token.getStartNode().getOffset(),token);
			}
			tokenKeys = (Long[])tokenMap.keySet().toArray(new Long[0]);
			Arrays.sort(tokenKeys);
			long subSentenceStart = mfMap.get(keys[numberOfMfs-2]);
			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceStart = tokenEnd;
				}
			}
			//export
			outputAS.add(subSentenceStart+1,pmfSentenceA.getEndNode().getOffset(),"PMFSentence",Factory.newFeatureMap());
			//remove pmfSentenceA when done.
			inputAS.remove(inputAS.get(pmfSentenceA.getId()));
		}
	} catch(Exception e) {
		e.printStackTrace();
	}
}
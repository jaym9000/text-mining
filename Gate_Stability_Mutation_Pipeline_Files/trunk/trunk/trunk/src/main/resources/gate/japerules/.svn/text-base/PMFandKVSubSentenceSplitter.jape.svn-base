Phase: mfAndKVSubSentenceSplitter
Input: PMFSentence KVSentence

Rule:ImpactSplitter
(
	{PMFSentence contains KVSentence}
	|
	{KVSentence contains PMFSentence}
):pmfkvsentence
-->
{
	try {
		Annotation mfAndKvSentenceA = (gate.Annotation)((gate.AnnotationSet)bindings.get("pmfkvsentence")).iterator().next();
		Annotation pmfSentence = (Annotation)inputAS.get("PMFSentence", mfAndKvSentenceA.getStartNode().getOffset(),mfAndKvSentenceA.getEndNode().getOffset()).iterator().next();
		Annotation kvSentence = (Annotation)inputAS.get("KVSentence", mfAndKvSentenceA.getStartNode().getOffset(),mfAndKvSentenceA.getEndNode().getOffset()).iterator().next();
		
		Annotation mfA = (Annotation)inputAS.get("MolecularFunction", mfAndKvSentenceA.getStartNode().getOffset(),mfAndKvSentenceA.getEndNode().getOffset()).iterator().next();
		Annotation kvA = (Annotation)inputAS.get("KineticVariable", mfAndKvSentenceA.getStartNode().getOffset(),mfAndKvSentenceA.getEndNode().getOffset()).iterator().next();
		
		//check which one is first
		boolean kvAFirst = kvA.getStartNode().getOffset() < mfA.getStartNode().getOffset();
		if(kvAFirst) {
			//leftmost
			Long start = mfAndKvSentenceA.getStartNode().getOffset();
			//get tokens between KV and PMF
			AnnotationSet tokens = inputAS.get("Token",kvA.getEndNode().getOffset(),mfA.getStartNode().getOffset());
			Map<Long,Annotation> tokenMap = new HashMap<Long,Annotation>();
			for(Annotation token : tokens) {
				tokenMap.put(token.getStartNode().getOffset(),token);
			}
			Long[] tokenKeys = (Long[]) tokenMap.keySet().toArray(new Long[0]);
			Arrays.sort(tokenKeys);
			long subSentenceEnd = mfA.getStartNode().getOffset();
			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceEnd = tokenStart;
					break;
				}
			}
			//export
			outputAS.add(start,subSentenceEnd,"KVSentence",Factory.newFeatureMap());

			//rightmost
			long subSentenceStart = kvA.getEndNode().getOffset();
			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceStart = tokenEnd;
				}
			}
			//export
			outputAS.add(subSentenceStart+1,mfAndKvSentenceA.getEndNode().getOffset(),"PMFSentence",Factory.newFeatureMap());
		}
		else {
			//leftmost
			Long start = mfAndKvSentenceA.getStartNode().getOffset();
			//get tokens between PMF and KV
			AnnotationSet tokens = inputAS.get("Token",mfA.getEndNode().getOffset(),kvA.getStartNode().getOffset());
			Map<Long,Annotation> tokenMap = new HashMap<Long,Annotation>();
			for(Annotation token : tokens) {
				tokenMap.put(token.getStartNode().getOffset(),token);
			}
			Long[] tokenKeys = (Long[]) tokenMap.keySet().toArray(new Long[0]);
			Arrays.sort(tokenKeys);
			long subSentenceEnd = mfA.getStartNode().getOffset();
			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceEnd = tokenStart;
					break;
				}
			}
			//export
			outputAS.add(start,subSentenceEnd,"PMFSentence",Factory.newFeatureMap());

			//rightmost
			long subSentenceStart = mfA.getEndNode().getOffset();
			for(long tokenStart : tokenKeys) {
				Annotation token = tokenMap.get(tokenStart);
				long tokenEnd = token.getEndNode().getOffset();
				FeatureMap features = token.getFeatures();
				if((features.get("kind").equals("punctuation") && doc.getContent().getContent(tokenEnd,tokenEnd+1).toString().matches("[\\s]"))|| doc.getContent().getContent(tokenStart,tokenEnd).toString().equals("and")) {
					subSentenceStart = tokenEnd;
				}
			}
			//export
			outputAS.add(subSentenceStart+1,mfAndKvSentenceA.getEndNode().getOffset(),"KVSentence",Factory.newFeatureMap());
		}
		//remove old sentences when done.
		inputAS.remove(inputAS.get(pmfSentence.getId()));
		inputAS.remove(inputAS.get(kvSentence.getId()));
		
	} catch(Exception e) {
	
	}	
}